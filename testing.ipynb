{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.load('outputs_torch.pt').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['samples', 'ref_stft', 'target', 'perceived_signals', 'doas'])\n",
      "samples.shape=torch.Size([64, 14, 256, 96])\n",
      "ref_stft.shape=torch.Size([64, 257, 96])\n",
      "target.shape=torch.Size([64, 256, 96])\n",
      "perceived_signals.shape=torch.Size([64, 2, 12160])\n",
      "doas.shape=torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "d = torch.load('data_batches/train06r076_37.pt')\n",
    "print(d.keys())\n",
    "samples, ref_stft, target, perceived_signals, doas = d['samples'], d['ref_stft'], d['target'], d['perceived_signals'], d['doas']\n",
    "print(f\"samples.shape={samples.shape}\")\n",
    "print(f\"ref_stft.shape={ref_stft.shape}\")\n",
    "print(f\"target.shape={target.shape}\")\n",
    "print(f\"perceived_signals.shape={perceived_signals.shape}\")\n",
    "print(f\"doas.shape={doas.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([2, 14, 256, 1120]), torch.Size([2, 257, 1120]), torch.Size([2, 256, 1120]), torch.Size([2, 2, 149119]), torch.Size([2, 2])]\n"
     ]
    }
   ],
   "source": [
    "d1 = {'samples': samples[:2], 'ref_stft': ref_stft[:2], 'target': target[:2], 'mixed_signals': perceived_signals[:2], 'doas': doas[:2]}\n",
    "print([v.shape for k,v in d1.items()])\n",
    "torch.save(d1, 'example_batch2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs.shape=torch.Size([8, 13, 256, 1120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "angles_idx = torch.argmax(probs, dim=1)\n",
    "vals = angles_idx[0].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([ 1063,  2157,  4026,  5348,  7552, 11676, 13289, 14329, 31553, 37984,\n",
      "        50508, 53235, 54000]),\n",
      "indices=tensor([ 9, 10, 11,  7,  2,  5,  3,  0,  1,  8, 12,  4,  6]))\n"
     ]
    }
   ],
   "source": [
    "print(vals[1].sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bsseval\n",
    "\n",
    "class SeparatedSource:\n",
    "\t\"\"\"Represents the part of the received sound that comes from this\n",
    "\tspecific source (angle).\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, ref_spec, probs):\n",
    "\t\t# The ref mic's spectrogram, shape=(Bmw, t)\n",
    "\t\tself.ref_spec = ref_spec\n",
    "\t\t# The model's output for this angle, shape=(w, t)\n",
    "\t\tself.probs = probs\n",
    "\t\n",
    "\tdef energy(self):\n",
    "\t\treturn torch.sum(self.probs * abs(self.ref_spec) ** 2)\n",
    "\t\n",
    "\tdef spec(self):\n",
    "\t\tmag = abs(self.ref_spec) * self.probs\n",
    "\t\tphase = torch.angle(self.ref_spec)\n",
    "\t\treturn mag * torch.exp(1j * phase)\n",
    "\t\n",
    "\tdef metrics(self):\n",
    "\t\t\"\"\"Retuns SDR, ISR, SIR, SAR.\"\"\"\n",
    "\t\tsep_signal = torch.istft(self.spec(), ...)  # <-- Finish me\n",
    "\t\t# TODO: maybe use the reference time signal directly?\n",
    "\t\tref_signal = torch.istft(self.ref_spec, ...)  # <-- Finish me\n",
    "\t\t\n",
    "\t\treturn bsseval.evaluate(\n",
    "\t\t\treferences=sep_signal.reshape(...),  # <-- Finish me\n",
    "\t\t\testimates=ref_signal.reshape(...),  # <-- Finish me\n",
    "\t\t\t# win=1*44100,\n",
    "\t\t\t# hop=1*44100,\n",
    "\t\t\t# mode='v4',\n",
    "\t\t\t# padding=True\n",
    "\t\t)\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef speaker_angles(cls, sources):\n",
    "\t\t\"\"\"Returns the 2 angle numbers where the speakers are (most\n",
    "\t\tlikely) located.\n",
    "\t\t\"\"\"\n",
    "\t\tenergies = [src.energy() for src in sources]\n",
    "\t\t# `argpartition` to get the indices, AKA angle numbers.\n",
    "\t\tpartitioned = np.argpartition(energies, angle_count - 2)\n",
    "\t\tmax_angles = tuple(partitioned[-2:])\n",
    "\t\treturn max_angles\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef sample_metrics(cls, ref_spec, samp_probs):\n",
    "\t\t\"\"\"Retuns the metrics for this sample's data & label.\"\"\"\n",
    "\t\t# `samp_probs`'s shape is (angle_count, w, t).\n",
    "\t\t# `sources[i]` is the separeted source coming from the direction\n",
    "\t\t# theta_i.\n",
    "\t\tsources = [SeparatedSource(ref_spec, probs) for probs in samp_probs]\n",
    "\t\t\n",
    "\t\tspeaker_angles = SeparatedSource.speaker_angles(sources)\n",
    "\t\tspeaker_metrics = [\n",
    "\t\t\tsources[angle.spec].metrics()\n",
    "\t\t\tfor angle in speaker_angles\n",
    "\t\t]\n",
    "\t\treturn speaker_metrics\n",
    "\n",
    "# Loop for each sample in the batch\n",
    "# for ref_spec, samp_probs in zip(batch_ref_specs, batch_outputs):\n",
    "\t# print(SeparatedSource.sample_metrics(ref_spec, samp_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1120])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_stft[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3090761., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.view(list(probs.shape)[:-2] + [-1]) @ torch.abs(ref_stft)\n",
    "torch.sum(probs * abs(ref_stft[1:]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeparatedSource(target, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_proj_generator_v2 import TrainLibriSpeechAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>record_name</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>reverb_time</th>\n",
       "      <th>SIR</th>\n",
       "      <th>theta</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>15664</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\3000\\1566...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.532481</td>\n",
       "      <td>180</td>\n",
       "      <td>1.185416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6345</td>\n",
       "      <td>64257</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\6345\\6425...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.280003</td>\n",
       "      <td>135</td>\n",
       "      <td>2.390319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5694</td>\n",
       "      <td>64029</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\5694\\6402...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.999142</td>\n",
       "      <td>60</td>\n",
       "      <td>1.786532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842</td>\n",
       "      <td>302203</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\8842\\3022...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.769222</td>\n",
       "      <td>150</td>\n",
       "      <td>1.344866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1462</td>\n",
       "      <td>170142</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\1462\\1701...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.778789</td>\n",
       "      <td>120</td>\n",
       "      <td>1.955771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>8297</td>\n",
       "      <td>275154</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\8297\\2751...</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.338972</td>\n",
       "      <td>30</td>\n",
       "      <td>1.362223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\2078\\1428...</td>\n",
       "      <td>1022</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.326748</td>\n",
       "      <td>135</td>\n",
       "      <td>1.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>6295</td>\n",
       "      <td>244435</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\6295\\2444...</td>\n",
       "      <td>1022</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.349233</td>\n",
       "      <td>30</td>\n",
       "      <td>1.677237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>6241</td>\n",
       "      <td>61943</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\6241\\6194...</td>\n",
       "      <td>1023</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.940246</td>\n",
       "      <td>150</td>\n",
       "      <td>1.701565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2902</td>\n",
       "      <td>9008</td>\n",
       "      <td>source_signals/LibriSpeech/dev-clean\\2902\\9008...</td>\n",
       "      <td>1023</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.389571</td>\n",
       "      <td>150</td>\n",
       "      <td>1.431728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker_name  record_name  \\\n",
       "0             3000        15664   \n",
       "1             6345        64257   \n",
       "2             5694        64029   \n",
       "3             8842       302203   \n",
       "4             1462       170142   \n",
       "...            ...          ...   \n",
       "2043          8297       275154   \n",
       "2044          2078       142845   \n",
       "2045          6295       244435   \n",
       "2046          6241        61943   \n",
       "2047          2902         9008   \n",
       "\n",
       "                                             audio_path  pair_id  reverb_time  \\\n",
       "0     source_signals/LibriSpeech/dev-clean\\3000\\1566...        0          0.4   \n",
       "1     source_signals/LibriSpeech/dev-clean\\6345\\6425...        0          0.2   \n",
       "2     source_signals/LibriSpeech/dev-clean\\5694\\6402...        1          0.3   \n",
       "3     source_signals/LibriSpeech/dev-clean\\8842\\3022...        1          0.4   \n",
       "4     source_signals/LibriSpeech/dev-clean\\1462\\1701...        2          0.4   \n",
       "...                                                 ...      ...          ...   \n",
       "2043  source_signals/LibriSpeech/dev-clean\\8297\\2751...     1021          0.2   \n",
       "2044  source_signals/LibriSpeech/dev-clean\\2078\\1428...     1022          0.2   \n",
       "2045  source_signals/LibriSpeech/dev-clean\\6295\\2444...     1022          0.2   \n",
       "2046  source_signals/LibriSpeech/dev-clean\\6241\\6194...     1023          0.4   \n",
       "2047  source_signals/LibriSpeech/dev-clean\\2902\\9008...     1023          0.3   \n",
       "\n",
       "           SIR  theta    radius  \n",
       "0    -0.532481    180  1.185416  \n",
       "1     1.280003    135  2.390319  \n",
       "2     1.999142     60  1.786532  \n",
       "3    -0.769222    150  1.344866  \n",
       "4     1.778789    120  1.955771  \n",
       "...        ...    ...       ...  \n",
       "2043  0.338972     30  1.362223  \n",
       "2044  1.326748    135  1.566237  \n",
       "2045 -1.349233     30  1.677237  \n",
       "2046  0.940246    150  1.701565  \n",
       "2047  1.389571    150  1.431728  \n",
       "\n",
       "[2048 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = TrainLibriSpeechAudio()\n",
    "df = gen.generate_dataset_meta()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waveform.shape=torch.Size([1, 222560])\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.transforms import Spectrogram, InverseSpectrogram\n",
    "import torchaudio\n",
    "\n",
    "FRAME_LENGTH = 512 # K\n",
    "NFFT = FRAME_LENGTH  # FFT length in STFT\n",
    "OVERLAP = 0.75  # Frame overlap in STFT\n",
    "HOP_LENGTH = int((1 - OVERLAP) * NFFT)  # Hop length in STFTHOP_LENGTH = \n",
    "FS = 16e3\n",
    "\n",
    "waveform, sample_rate = torchaudio.load('source_signals/LibriSpeech/train-clean-100/27/124992/27-124992-0001.flac')\n",
    "waveform = waveform.cuda()\n",
    "print(f\"waveform.shape={waveform.shape}\")\n",
    "\n",
    "spectrogram = Spectrogram(\n",
    "    n_fft=NFFT,\n",
    "    win_length=NFFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    power=None  # Complex spectrum\n",
    ").to('cuda')\n",
    "\n",
    "\n",
    "ispectrogram = InverseSpectrogram(\n",
    "    n_fft=NFFT,\n",
    "    win_length=NFFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    ").to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_len(waveform, len):\n",
    "    wfl = waveform[:, :len]\n",
    "    stft = spectrogram(wfl)\n",
    "    istft = ispectrogram(stft)\n",
    "    print(f\"original shape={wfl.shape}\")\n",
    "    print(f\"stft shape={stft.shape}\")\n",
    "    print(f\"istft(stft) shape={istft.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape=torch.Size([1, 163760])\n",
      "stft shape=torch.Size([1, 257, 1280])\n",
      "istft(stft) shape=torch.Size([1, 163712])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163760.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_len(waveform, int(16000*10.235))\n",
    "1271//16 * 16\n",
    "16000*10.235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape=torch.Size([1, 12220])\n",
      "stft shape=torch.Size([1, 257, 96])\n",
      "istft(stft) shape=torch.Size([1, 12160])\n"
     ]
    }
   ],
   "source": [
    "print_len(waveform, 12220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [01:24<00:00, 13.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from audio_dataset import DictTorchPartedDataset\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "\n",
    "device='cuda'\n",
    "train_dataset = DictTorchPartedDataset('data_batches', 'train06r076' , ['samples', 'ref_stft', 'target'], real_batch_size=64, virtual_batch_size=1, device=device)\n",
    "\n",
    "for i in tqdm(range(4864, len(train_dataset))):\n",
    "    samples, _, _ = train_dataset[i]\n",
    "    if torch.any(torch.isnan(samples)):\n",
    "        print(f\"{i} has {len(torch.isnan(samples) / samples.numel() * 100)}% nans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_batches/__SSS__test10tgtprc_0.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m d \u001b[38;5;241m=\u001b[39m {k:v[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{i} : _{i // 64}.pt, member {i % 64}\")\n",
    "\n",
    "data = torch.load('data_batches/train06r076_75.pt')\n",
    "d = {k:v[30] for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples.shape=torch.Size([14, 256, 96])\n",
      "ref_stft.shape=torch.Size([257, 96])\n",
      "target.shape=torch.Size([256, 96])\n",
      "perceived_signals.shape=torch.Size([2, 12160])\n",
      "doas.shape=torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "samples, ref_stft, target, perceived_signals, doas = d['samples'], d['ref_stft'], d['target'], d['perceived_signals'], d['doas']\n",
    "print(f\"samples.shape={samples.shape}\")\n",
    "print(f\"ref_stft.shape={ref_stft.shape}\")\n",
    "print(f\"target.shape={target.shape}\")\n",
    "print(f\"perceived_signals.shape={perceived_signals.shape}\")\n",
    "print(f\"doas.shape={doas.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perceived_signals[1][torch.isnan(perceived_signals[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.load('data_batches/__SSS__test10tgtprc_0.pt')\n",
    "d = {k: torch.tensor(v[:2].detach().cpu().numpy()) for k,v in data.items()}\n",
    "d['probs'] = torch.tensor(probs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d, 'samples_test1405.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "mat_path = 'timit_rir/Impulse_response_Acoustic_Lab_Bar-Ilan_University_(Reverberation_0.160s)_3-3-3-8-3-3-3_1m_000.mat'\n",
    "mat = scipy.io.loadmat(mat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir = mat['impulse_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape=torch.Size([8, 480000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agadi\\AppData\\Local\\Temp\\ipykernel_15444\\196252497.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = torch.tensor(rir.T, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "a = torch.tensor(rir.T, dtype=torch.float32)\n",
    "print(f\"a.shape={a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 480000])\n"
     ]
    }
   ],
   "source": [
    "rir = a.flip(dims=(0, ))\n",
    "print(rir.shape)\n",
    "waveform = torchaudio.transforms.Resample(48000, 16000)(rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_mat_as_torch(mat_path: str) -> torch.tensor:\n",
    "    mat = scipy.io.loadmat(mat_path)\n",
    "    data_impulse_response = mat['impulse_response']\n",
    "    impulse_response_fs = 48000\n",
    "\n",
    "    rir = torch.tensor(data_impulse_response.T, dtype=torch.float32)\n",
    "    # Reorder microphones\n",
    "    if True:\n",
    "        rir = rir.flip((0, ))\n",
    "        \n",
    "    # 8 x XXX\n",
    "    waveform = torchaudio.transforms.Resample(impulse_response_fs, 16000)(rir)\n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 160000])\n"
     ]
    }
   ],
   "source": [
    "wav1 = _load_mat_as_torch('timit_rir/Impulse_response_Acoustic_Lab_Bar-Ilan_University_(Reverberation_0.160s)_3-3-3-8-3-3-3_1m_000.mat')\n",
    "print(wav1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
