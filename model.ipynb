{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from helpers.plot import plot_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning_trainer import UnetDACLighting\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger, TensorBoardLogger\n",
    "\n",
    "from audio_dataset import DictTorchPartedDataset, PinDictTorchPartedDataset\n",
    "from typing import List\n",
    "from trainer import AudioTrainer\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from unet_dac import UnetDAC\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import NUM_MICS, ANGLE_RES\n",
    "\n",
    "L_v = 96\n",
    "K = 256\n",
    "# INPUT_LEN = 64\n",
    "# VIRTUAL_BATCH_SIZE = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UnetDAC(L=L_v, K=K, M=NUM_MICS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: tb_logs\\unet_doa_batch64_lr1e-3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | UnetDAC          | 1.9 M \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.772     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bbc1607dc744eeba2cb85e1ac995e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agadi\\miniconda3\\envs\\audio_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd4a19349604de9a280127eb44308fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddc2d339e4247f9b99dd57c78945e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5080553ac2484ec4a59617f6f6a0a8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11786d7f03c44c06961f550ac823450b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e5cee0b6654410b101eb476d3aa834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd15ab7cba946b1ad9f91c9d8357cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d420d0b35c544bae8e2f066e65f0823b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580568829c594fa58240ae190fe11e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_bs = 16\n",
    "lr: float = 1e-3\n",
    "\n",
    "model_name = \"unet_doa_batch{train_bs}_lr{lr:.0e}\"\n",
    "train_dataset = PinDictTorchPartedDataset('data_batches', 'train06r076' , ['samples', 'ref_stft', 'target'], real_batch_size=64, virtual_batch_size=1, device=device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_bs, shuffle=True, num_workers=4, persistent_workers=True, prefetch_factor=16)\n",
    "test_dataset = PinDictTorchPartedDataset('data_batches', 'test10tgtprc' , ['samples', 'ref_stft', 'target'], real_batch_size=30, virtual_batch_size=1, device=device)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=30, shuffle=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_lighting = UnetDACLighting(model, criterion, lr, device=device)\n",
    "# wandb_logger = WandbLogger(log_model=\"all\", project='AudioDOA', name='bs=64,sig0.6 clean. 0.76 with reverb')\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=model_name)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=100,\n",
    "                    callbacks=[EarlyStopping(monitor=\"train_loss\", mode=\"min\", patience=3)],\n",
    "                    default_root_dir=model_name,\n",
    "                    log_every_n_steps=9,\n",
    "                    logger=logger)\n",
    "trainer.fit(model_lighting, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 256, 96])\n"
     ]
    }
   ],
   "source": [
    "i0 = train_dataset[0][0].cuda()\n",
    "print(i0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Loading checkpoint file checkpoints.pt\n",
      "*** best_loss=2.36 ewi=0\n",
      "--- EPOCH 1/100 ---\n",
      "train_batch (Avg. Loss 2.371): 100%|██████████| 8/8 [00:29<00:00,  3.70s/it]\n",
      "test_batch (Avg. Loss 2.556): 100%|██████████| 4/4 [00:37<00:00,  9.34s/it]\n",
      "train_batch (Avg. Loss 2.354): 100%|██████████| 8/8 [00:25<00:00,  3.24s/it]\n",
      "test_batch (Avg. Loss 2.581): 100%|██████████| 4/4 [00:40<00:00, 10.17s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 2\n",
      "train_batch (Avg. Loss 2.357): 100%|██████████| 8/8 [00:28<00:00,  3.59s/it]\n",
      "test_batch (Avg. Loss 2.561): 100%|██████████| 4/4 [00:35<00:00,  8.79s/it]\n",
      "train_batch (Avg. Loss 2.351): 100%|██████████| 8/8 [00:27<00:00,  3.41s/it]\n",
      "test_batch (Avg. Loss 2.558): 100%|██████████| 4/4 [00:32<00:00,  8.17s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 4\n",
      "train_batch (Avg. Loss 2.359): 100%|██████████| 8/8 [00:26<00:00,  3.31s/it]\n",
      "test_batch (Avg. Loss 2.566): 100%|██████████| 4/4 [00:32<00:00,  8.08s/it]\n",
      "train_batch (Avg. Loss 2.350): 100%|██████████| 8/8 [00:27<00:00,  3.40s/it]\n",
      "test_batch (Avg. Loss 2.551): 100%|██████████| 4/4 [00:32<00:00,  8.15s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 6\n",
      "train_batch (Avg. Loss 2.352): 100%|██████████| 8/8 [00:26<00:00,  3.28s/it]\n",
      "test_batch (Avg. Loss 2.550): 100%|██████████| 4/4 [00:30<00:00,  7.58s/it]\n",
      "train_batch (Avg. Loss 2.351): 100%|██████████| 8/8 [00:26<00:00,  3.27s/it]\n",
      "test_batch (Avg. Loss 2.549): 100%|██████████| 4/4 [00:33<00:00,  8.26s/it]\n",
      "train_batch (Avg. Loss 2.345): 100%|██████████| 8/8 [00:28<00:00,  3.51s/it]\n",
      "test_batch (Avg. Loss 2.537): 100%|██████████| 4/4 [00:31<00:00,  7.78s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 9\n",
      "train_batch (Avg. Loss 2.353): 100%|██████████| 8/8 [00:24<00:00,  3.02s/it]\n",
      "test_batch (Avg. Loss 2.554): 100%|██████████| 4/4 [00:32<00:00,  8.10s/it]\n",
      "--- EPOCH 11/100 ---\n",
      "train_batch (Avg. Loss 2.343): 100%|██████████| 8/8 [00:26<00:00,  3.29s/it]\n",
      "test_batch (Avg. Loss 2.549): 100%|██████████| 4/4 [00:29<00:00,  7.32s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 11\n",
      "train_batch (Avg. Loss 2.339): 100%|██████████| 8/8 [00:25<00:00,  3.16s/it]\n",
      "test_batch (Avg. Loss 2.543): 100%|██████████| 4/4 [00:28<00:00,  7.05s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 12\n",
      "train_batch (Avg. Loss 2.337): 100%|██████████| 8/8 [00:22<00:00,  2.87s/it]\n",
      "test_batch (Avg. Loss 2.557): 100%|██████████| 4/4 [00:39<00:00,  9.82s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 13\n",
      "train_batch (Avg. Loss 2.336): 100%|██████████| 8/8 [00:25<00:00,  3.22s/it]\n",
      "test_batch (Avg. Loss 2.542): 100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 14\n",
      "train_batch (Avg. Loss 2.336): 100%|██████████| 8/8 [00:27<00:00,  3.42s/it]\n",
      "test_batch (Avg. Loss 2.539): 100%|██████████| 4/4 [00:28<00:00,  7.12s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 15\n",
      "train_batch (Avg. Loss 2.338): 100%|██████████| 8/8 [00:27<00:00,  3.39s/it]\n",
      "test_batch (Avg. Loss 2.550): 100%|██████████| 4/4 [00:36<00:00,  9.11s/it]\n",
      "train_batch (Avg. Loss 2.342): 100%|██████████| 8/8 [00:28<00:00,  3.54s/it]\n",
      "test_batch (Avg. Loss 2.541): 100%|██████████| 4/4 [00:33<00:00,  8.37s/it]\n",
      "train_batch (Avg. Loss 2.341): 100%|██████████| 8/8 [00:28<00:00,  3.62s/it]\n",
      "test_batch (Avg. Loss 2.566): 100%|██████████| 4/4 [00:34<00:00,  8.63s/it]\n",
      "train_batch (Avg. Loss 2.336): 100%|██████████| 8/8 [00:27<00:00,  3.48s/it]\n",
      "test_batch (Avg. Loss 2.553): 100%|██████████| 4/4 [00:42<00:00, 10.53s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 19\n",
      "train_batch (Avg. Loss 2.335): 100%|██████████| 8/8 [00:25<00:00,  3.17s/it]\n",
      "test_batch (Avg. Loss 2.556): 100%|██████████| 4/4 [00:39<00:00,  9.88s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 20\n",
      "--- EPOCH 21/100 ---\n",
      "train_batch (Avg. Loss 2.334): 100%|██████████| 8/8 [00:25<00:00,  3.21s/it]\n",
      "test_batch (Avg. Loss 2.540): 100%|██████████| 4/4 [00:31<00:00,  7.78s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 21\n",
      "train_batch (Avg. Loss 2.332): 100%|██████████| 8/8 [00:31<00:00,  3.88s/it]\n",
      "test_batch (Avg. Loss 2.545): 100%|██████████| 4/4 [00:29<00:00,  7.41s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 22\n",
      "train_batch (Avg. Loss 2.331): 100%|██████████| 8/8 [00:26<00:00,  3.30s/it]\n",
      "test_batch (Avg. Loss 2.535): 100%|██████████| 4/4 [00:32<00:00,  8.09s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 23\n",
      "train_batch (Avg. Loss 2.328): 100%|██████████| 8/8 [00:31<00:00,  3.93s/it]\n",
      "test_batch (Avg. Loss 2.536): 100%|██████████| 4/4 [00:34<00:00,  8.59s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 24\n",
      "train_batch (Avg. Loss 2.326): 100%|██████████| 8/8 [00:24<00:00,  3.11s/it]\n",
      "test_batch (Avg. Loss 2.547): 100%|██████████| 4/4 [00:38<00:00,  9.73s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 25\n",
      "train_batch (Avg. Loss 2.322): 100%|██████████| 8/8 [00:23<00:00,  2.91s/it]\n",
      "test_batch (Avg. Loss 2.537): 100%|██████████| 4/4 [00:31<00:00,  7.79s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 26\n",
      "train_batch (Avg. Loss 2.317): 100%|██████████| 8/8 [00:26<00:00,  3.34s/it]\n",
      "test_batch (Avg. Loss 2.532): 100%|██████████| 4/4 [00:32<00:00,  8.02s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 27\n",
      "train_batch (Avg. Loss 2.318): 100%|██████████| 8/8 [00:26<00:00,  3.36s/it]\n",
      "test_batch (Avg. Loss 2.538): 100%|██████████| 4/4 [00:32<00:00,  8.08s/it]\n",
      "train_batch (Avg. Loss 2.319): 100%|██████████| 8/8 [00:25<00:00,  3.17s/it]\n",
      "test_batch (Avg. Loss 2.535): 100%|██████████| 4/4 [00:30<00:00,  7.68s/it]\n",
      "train_batch (Avg. Loss 2.316): 100%|██████████| 8/8 [00:26<00:00,  3.31s/it]\n",
      "test_batch (Avg. Loss 2.538): 100%|██████████| 4/4 [00:29<00:00,  7.48s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 30\n",
      "--- EPOCH 31/100 ---\n",
      "train_batch (Avg. Loss 2.311): 100%|██████████| 8/8 [00:30<00:00,  3.81s/it]\n",
      "test_batch (Avg. Loss 2.537): 100%|██████████| 4/4 [00:33<00:00,  8.28s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 31\n",
      "train_batch (Avg. Loss 2.320): 100%|██████████| 8/8 [00:27<00:00,  3.43s/it]\n",
      "test_batch (Avg. Loss 2.561): 100%|██████████| 4/4 [00:31<00:00,  7.90s/it]\n",
      "train_batch (Avg. Loss 2.317): 100%|██████████| 8/8 [00:28<00:00,  3.51s/it]\n",
      "test_batch (Avg. Loss 2.527): 100%|██████████| 4/4 [00:32<00:00,  8.19s/it]\n",
      "train_batch (Avg. Loss 2.302): 100%|██████████| 8/8 [00:26<00:00,  3.35s/it]\n",
      "test_batch (Avg. Loss 2.561): 100%|██████████| 4/4 [00:29<00:00,  7.33s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 34\n",
      "train_batch (Avg. Loss 2.299): 100%|██████████| 8/8 [00:25<00:00,  3.14s/it]\n",
      "test_batch (Avg. Loss 2.546): 100%|██████████| 4/4 [00:30<00:00,  7.51s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 35\n",
      "train_batch (Avg. Loss 2.291): 100%|██████████| 8/8 [00:25<00:00,  3.18s/it]\n",
      "test_batch (Avg. Loss 2.560): 100%|██████████| 4/4 [00:29<00:00,  7.37s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 36\n",
      "train_batch (Avg. Loss 2.292): 100%|██████████| 8/8 [00:25<00:00,  3.14s/it]\n",
      "test_batch (Avg. Loss 2.548): 100%|██████████| 4/4 [00:27<00:00,  6.83s/it]\n",
      "train_batch (Avg. Loss 2.292): 100%|██████████| 8/8 [00:25<00:00,  3.14s/it]\n",
      "test_batch (Avg. Loss 2.522): 100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n",
      "train_batch (Avg. Loss 2.288): 100%|██████████| 8/8 [00:27<00:00,  3.46s/it]\n",
      "test_batch (Avg. Loss 2.533): 100%|██████████| 4/4 [00:34<00:00,  8.75s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 39\n",
      "train_batch (Avg. Loss 2.287): 100%|██████████| 8/8 [00:26<00:00,  3.29s/it]\n",
      "test_batch (Avg. Loss 2.545): 100%|██████████| 4/4 [00:32<00:00,  8.12s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 40\n",
      "--- EPOCH 41/100 ---\n",
      "train_batch (Avg. Loss 2.281): 100%|██████████| 8/8 [00:28<00:00,  3.54s/it]\n",
      "test_batch (Avg. Loss 2.539): 100%|██████████| 4/4 [00:31<00:00,  7.99s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 41\n",
      "train_batch (Avg. Loss 2.272): 100%|██████████| 8/8 [00:27<00:00,  3.45s/it]\n",
      "test_batch (Avg. Loss 2.523): 100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n",
      "*** Saved checkpoint checkpoints.pt at epoch 42\n",
      "train_batch (Avg. Loss 2.293): 100%|██████████| 8/8 [00:26<00:00,  3.32s/it]\n",
      "test_batch (Avg. Loss 2.530): 100%|██████████| 4/4 [00:26<00:00,  6.68s/it]\n",
      "train_batch (Avg. Loss 2.299): 100%|██████████| 8/8 [00:27<00:00,  3.39s/it]\n",
      "test_batch (Avg. Loss 2.544): 100%|██████████| 4/4 [00:28<00:00,  7.21s/it]\n",
      "train_batch (Avg. Loss 2.278): 100%|██████████| 8/8 [00:24<00:00,  3.01s/it]\n",
      "test_batch (Avg. Loss 2.548): 100%|██████████| 4/4 [00:27<00:00,  6.79s/it]\n",
      "train_batch (Avg. Loss 2.285): 100%|██████████| 8/8 [00:25<00:00,  3.19s/it]\n",
      "test_batch (Avg. Loss 2.558): 100%|██████████| 4/4 [00:26<00:00,  6.72s/it]\n",
      "train_batch (Avg. Loss 2.274): 100%|██████████| 8/8 [00:24<00:00,  3.05s/it]\n",
      "test_batch (Avg. Loss 2.542): 100%|██████████| 4/4 [00:26<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# dataset = DistributedTorchDataset('data_batches', 'train' , ['samples', 'ref_stft', 'target'])\n",
    "train_dataset = DictTorchPartedDataset('data_batches', 'trainv2' , ['samples', 'ref_stft', 'target'], real_batch_size=64, virtual_batch_size=1, device=device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataset = DictTorchPartedDataset('data_batches', 'testv2' , ['samples', 'ref_stft', 'target'], real_batch_size=30, virtual_batch_size=1, device=device)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr: float = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "trainer = AudioTrainer(model=model, loss_fn=criterion, optimizer=optimizer, device=device)\n",
    "fit_res = trainer.fit(train_dataloader, test_dataloader, num_epochs=100, checkpoints='checkpoints', early_stopping=5, print_every=10)\n",
    "# fig, axes = plot_fit(fit_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_TRAIN_EPOCHS = 100\n",
    "# lr: float = 2e-3\n",
    "# epochs: int = 100\n",
    "# early_stopping: int = 3\n",
    "# mininbatch_size: int = 16\n",
    "\n",
    "# train_statistics = []\n",
    "# dataset = DistributedTorchDataset('data_batches', 'train' , ['samples', 'ref_stft', 'target'], virtual_batch_size=1)\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_ref_specs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m \t\t\u001b[38;5;28;01mreturn\u001b[39;00m speaker_metrics\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Loop for each sample in the batch\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ref_spec, samp_probs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mbatch_ref_specs\u001b[49m, batch_outputs):\n\u001b[0;32m     64\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(SeparatedSource\u001b[38;5;241m.\u001b[39msample_metrics(ref_spec, samp_probs))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_ref_specs' is not defined"
     ]
    }
   ],
   "source": [
    "import bsseval\n",
    "\n",
    "class SeparatedSource:\n",
    "\t\"\"\"Represents the part of the received sound that comes from this\n",
    "\tspecific source (angle).\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, ref_spec, probs):\n",
    "\t\t# The ref mic's spectrogram, shape=(Bmw, t)\n",
    "\t\tself.ref_spec = ref_spec\n",
    "\t\t# The model's output for this angle, shape=(w, t)\n",
    "\t\tself.probs = probs\n",
    "\t\n",
    "\tdef energy(self):\n",
    "\t\treturn torch.sum(self.probs * abs(self.ref_spec) ** 2)\n",
    "\t\n",
    "\tdef spec(self):\n",
    "\t\tmag = abs(self.ref_spec) * self.probs\n",
    "\t\tphase = torch.angle(self.ref_spec)\n",
    "\t\treturn mag * torch.exp(1j * phase)\n",
    "\t\n",
    "\tdef metrics(self):\n",
    "\t\t\"\"\"Retuns SDR, ISR, SIR, SAR.\"\"\"\n",
    "\t\tsep_signal = torch.istft(self.spec(), ...)  # <-- Finish me\n",
    "\t\t# TODO: maybe use the reference time signal directly?\n",
    "\t\tref_signal = torch.istft(self.ref_spec, ...)  # <-- Finish me\n",
    "\t\t\n",
    "\t\treturn bsseval.evaluate(\n",
    "\t\t\treferences=sep_signal.reshape(...),  # <-- Finish me\n",
    "\t\t\testimates=ref_signal.reshape(...),  # <-- Finish me\n",
    "\t\t\t# win=1*44100,\n",
    "\t\t\t# hop=1*44100,\n",
    "\t\t\t# mode='v4',\n",
    "\t\t\t# padding=True\n",
    "\t\t)\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef speaker_angles(cls, sources):\n",
    "\t\t\"\"\"Returns the 2 angle numbers where the speakers are (most\n",
    "\t\tlikely) located.\n",
    "\t\t\"\"\"\n",
    "\t\tenergies = [src.energy() for src in sources]\n",
    "\t\t# `argpartition` to get the indices, AKA angle numbers.\n",
    "\t\tpartitioned = np.argpartition(energies, angle_count - 2)\n",
    "\t\tmax_angles = tuple(partitioned[-2:])\n",
    "\t\treturn max_angles\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef sample_metrics(cls, ref_spec, samp_probs):\n",
    "\t\t\"\"\"Retuns the metrics for this sample's data & label.\"\"\"\n",
    "\t\t# `samp_probs`'s shape is (angle_count, w, t).\n",
    "\t\t# `sources[i]` is the separeted source coming from the direction\n",
    "\t\t# theta_i.\n",
    "\t\tsources = [SeparatedSource(ref_spec, probs) for probs in samp_probs]\n",
    "\t\t\n",
    "\t\tspeaker_angles = SeparatedSource.speaker_angles(sources)\n",
    "\t\tspeaker_metrics = [\n",
    "\t\t\tsources[angle.spec].metrics()\n",
    "\t\t\tfor angle in speaker_angles\n",
    "\t\t]\n",
    "\t\treturn speaker_metrics\n",
    "\n",
    "# Loop for each sample in the batch\n",
    "for ref_spec, samp_probs in zip(batch_ref_specs, batch_outputs):\n",
    "\tprint(SeparatedSource.sample_metrics(ref_spec, samp_probs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop - manual ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# for epoch in range(epochs):\n",
    "#     running_loss = 0.0\n",
    "#     print(f'--- epoch {epoch + 1} ---')\n",
    "\n",
    "#     # Train on minibatches\n",
    "#     for i, minibatch in tqdm(enumerate(dataloader), desc=f'Epoch {epoch} trainig batches', total=len(dataloader)):\n",
    "#         samples, ref_abs_square, target = minibatch\n",
    "#         # print(f\"hello I am a minibatch! my dimensions are:\")\n",
    "#         # print(f\"samples.shape={samples.shape}\\nref_stft.shape={ref_stft.shape}\\ntarget.shape={target.shape}\")\n",
    "#         # Forward + backward + optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(samples)\n",
    "#         # TODO\n",
    "#         # output_directions = torch.dot(outputs, ref_stft * ref_stft.T)\n",
    "#         # output_angle = torch.argmax(output_directions, axis=1)\n",
    "#         loss = criterion(outputs, target // ANGLE_RES)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Statistics\n",
    "#         running_loss += loss.item() / VIRTUAL_BATCH_SIZE\n",
    "#         losses.append({'epoch': epoch, 'batch': i, 'loss': loss.item()})\n",
    "#         if i % 8 == 7:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss :.3f}')\n",
    "#             # running_loss = 0.0\n",
    "\n",
    "#     # Validation on minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df = pd.DataFrame(losses)\n",
    "# display(loss_df)\n",
    "# print(f\"Average loss: {loss_df.loss.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Trainer, TrainingArguments\n",
    "# from transformers.data.data_collator import DataCollator\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',          # output directory\n",
    "#     num_train_epochs=100,              # total number of training epochs\n",
    "#     per_device_train_batch_size=1,  # batch size per device during training\n",
    "#     logging_dir='./logs',            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    "#     learning_rate=0.001,             # learning rate\n",
    "# )\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=training_args.learning_rate)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# train_dataset = DictTorchPartedDataset('data_batches', 'train' , ['samples', 'ref_stft', 'target'], real_batch_size=64, virtual_batch_size=1, device=device)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# test_dataset = DictTorchPartedDataset('data_batches', 'test' , ['samples', 'ref_stft', 'target'], real_batch_size=30, virtual_batch_size=1, device=device)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# def collate_fn(features):\n",
    "#     # Assuming features is a list of dictionaries with your custom keys\n",
    "    \n",
    "#     return {'data': [feature[0] for feature in features]}\n",
    "    \n",
    "    \n",
    "# # Define the Hugging Face Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "#     args=training_args,                  # training arguments, defined above\n",
    "#     train_dataset=train_dataset,            # training dataset\n",
    "#     eval_dataset=test_dataset,                   # evaluation dataset\n",
    "#     compute_metrics=None,                # any additional metrics you want to compute\n",
    "#     optimizers=(optimizer, None),        # (optimizer, scheduler), scheduler is None here\n",
    "#     data_collator=collate_fn                   # data collator, default collate_fn for torch DataLoader\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a=1.689090371131897, loss_b=1.689090371131897\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_a = criterion(torch.tensor([[0,0,0,0,1.,0,0,0,0,0,0,0,0]]), torch.tensor([[0,0,0,0,1.,0,0,0,0,0,0,0,0]]))\n",
    "loss_b = criterion(torch.tensor([[0,0,0,0,1.,0,0,0,0,0,0,0,0]]), torch.tensor([4]))\n",
    "print(f\"loss_a={loss_a}, loss_b={loss_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = torch.load('data_batches/trainv2_0.pt')\n",
    "for k,v in d1.items():\n",
    "    d1[k] = torch.tensor(v[:2].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state = torch.load('checkpoints.pt')\n",
    "model.load_state_dict(saved_state['model_state'])\n",
    "d1 = torch.load('example_batch2.pt')\n",
    "outputs = model(d1['samples'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['samples', 'ref_stft', 'target', 'perceived_signals', 'doas', 'probs'])\n"
     ]
    }
   ],
   "source": [
    "d1['probs'] = torch.tensor(outputs.cpu().detach().numpy())\n",
    "print(d1.keys())\n",
    "# for k,v in d1.items():\n",
    "    # d1[k] = torch.tensor(v.cpu().detach().numpy())\n",
    "torch.save(d1, 'example_batch2.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
